# configfile: "config/config.yaml"

import datetime
import glob
import shutil
from pathlib import Path
from os.path import join
datestring = datetime.date.today().strftime("%d-%m-%y")
DATESTRING = {'today': datestring}

from loguru import logger as lg

# include: "rules/download_snake.smk"
include: "rules/blast_missing_seqs.smk"

lg.info(f"Ribosome list file: {config['ribosomefile']}")
lg.info(f"Genus: {config['genus']}")

handle = open(config['ribosomefile'], 'r')
genus = open(config['genus'], 'r')

GENUS = [liner.rstrip() for liner in genus]
SAMPLES = [lin.rstrip() for lin in handle]

# print(DATESTRING, SAMPLES, GENUS)

rule all:
    input:
        # f"{config['outdir']}/logs/completed.txt",
        # f"{config['outdir']}/logs/newroot.txt",
        f"{config['outdir']}/logs/gunzip_complete.txt",
        config["cleannames"],
        f"{config['outdir']}/logs/conversion_complete.txt",
        f"{config['outdir']}/results/Allnamesmapoverdatabase.txt",
        atccs=expand(f"{config['outdir']}/results/ribosome_db/{{sample}}.dmnd", sample=SAMPLES),
        missing=f"{config['outdir']}/results/strains_missing_ribos.txt",
        conc=f"{config['outdir']}/results/{DATESTRING['today']}.concatenated_ribosomal_proteins_db.fasta",
        extr=f"{config['outdir']}/logs/extracted_complete.txt",
        subtest=f"{config['outdir']}/results/{DATESTRING['today']}.concatenated_ribosomal_proteins_db.fasta_2",
        dmnd=f"{config['outdir']}/logs/blast_complete.txt",
        report=f"{config['outdir']}/results/report.html"


def glob_files():
      suffixes = ['*.gbff', '*.gbf', '*.gbk', '*.gb', '*.genbank']
      files_glob = []
      required=config['download_genbank']['options']
      for suf in suffixes:
          files_glob.append([Path(fa).name for fa in glob.glob(suf)])
    #   lg.info(files_glob)
      if 'no' in required:
          shell(f"touch '{config['outdir']}/logs/gunzip_complete.txt'")
      else:
          pass
    #   lg.info("files glob", files_glob)
      return files_glob

rule convert_nucl_protein:
    input:
        files = glob_files(),
        gunz = f"{config['outdir']}/logs/gunzip_complete.txt"
    output:
        f"{config['outdir']}/logs/conversion_complete.txt"
    params:
        type=config['protein_dna']['options'],
        required=config['download_genbank']['options']
    threads:
        config['threads']
    run:
        if 'yes' in params.required:
            outfile2 = open("cleannames.txt", 'w')
        for file in input.files:
            if 'yes' in params.required:
                outfile2.write(f"{Path(file).name}\n")
            if 'protein' in params.type:
                print("indeed I'm here in protein")
                shell(f"python {config['workflow_dir']}/scripts/gbk2faa.py {{file}}")
                print("gbk2faa executed")
            elif 'dna' in params.type:
                shell(f"python {config['workflow_dir']}/scripts/gbk2ffn.py {{file}}")
        shell(f"touch '{config['outdir']}/logs/conversion_complete.txt'")

rule create_mapover:
    input:
        f"{config['outdir']}/logs/conversion_complete.txt"
    output:
        f"{config['outdir']}/results/Allnamesmapoverdatabase.txt"
    params:
        required=config['download_genbank']['options']
    run:
        if 'yes' in params.required:	  
            shell("for file in GCF*gbff; do echo $file; grep DEFINITION $file; done > whichsequenceiswhich.txt")
            shell(f"python {config['workflow_dir']}/scripts/makeconsdatabasemapping.py > {config['outdir']}/Allnamesmapoverdatabase.txt")
        else:
            shell(f"touch {config['outdir']}/results/Allnamesmapoverdatabase.txt")


rule extract_from_gbk:
    input:
        check=glob.glob(config['cleannames']),
        mapov=f"{config['outdir']}/results/Allnamesmapoverdatabase.txt"
    output:
        f"{config['outdir']}/results/{DATESTRING['today']}.extracted.fasta",
        f"{config['outdir']}/logs/extracted_complete.txt"
    params:
        config['protein_dna']['options']
    run:
        inputs = [lin.rstrip() for lin in open(''.join(input.check),'r')]
        for cleanname in inputs:
            shell(f"python {config['workflow_dir']}/scripts/extract_ribo_seqs_from_gbk.py {{cleanname}} {{params}} {config['outdir']}")
        shell(f"touch '{config['outdir']}/logs/extracted_complete.txt'")


rule check_for_missing_seqs:
    input:
        extracted=f"{config['outdir']}/results/{DATESTRING['today']}.extracted.fasta",
        comple=f"{config['outdir']}/logs/extracted_complete.txt"
    output:
        f"{config['outdir']}/results/{DATESTRING['today']}.concatenated_ribosomal_proteins_db.fasta",
        f"{config['outdir']}/results/strains_missing_ribos.txt"
    params:
        protein_dna = config['protein_dna']['options'],
        ribo_name_field = config['ribo_name_field']['options']
    run:
        shell(f"python {config['workflow_dir']}/scripts/ribo_concat_diamond.py {{input.extracted}} {{params.ribo_name_field}} {config['outdir']}")


rule concatenate_with_previous:
    input:
        newput = f"{config['outdir']}/results/{DATESTRING['today']}.concatenated_ribosomal_proteins_db.fasta",
        nextput = f"{config['outdir']}/results/{DATESTRING['today']}.concatenated_ribosomal_proteins_db.fasta_2"
    output:
        f"{config['outdir']}/results/{DATESTRING['today']}.updateriboprot.fasta"
    log:
        log=f"{config['outdir']}/logs/concatenate_with_previous.log"
    run:
        if (config["previous_files"]):
            add_previous_files = config["previous_files"]
        else:
            add_previous_files = ""
        shell(f"(cat {add_previous_files} {{input.newput}} {{input.nextput}} > {{output}}) 2>> {{log}}")


rule deduplicate:
     input:
         f"{config['outdir']}/results/{DATESTRING['today']}.updateriboprot.fasta"
     output:
         dedupe = f"{config['outdir']}/results/{DATESTRING['today']}.updateriboprot.fastadedupe.fasta",
     log:
         log=f"{config['outdir']}/logs/deduplicate.log"
     shell:
         f"python {config['workflow_dir']}/scripts/check_not_duplicatedIDs.py {{input}}"

rule align:
     input:
         f"{config['outdir']}/results/{DATESTRING['today']}.updateriboprot.fastadedupe.fasta"
     output:
         f"{config['outdir']}/results/{DATESTRING['today']}.updateriboprotdedupe.aln"
     threads:
         config['threads']
     log:
         log=f"{config['outdir']}/logs/align.log"
     run:
         shell("(mafft --retree 3 --maxiterate 3 --thread {threads} {input} > {output})")

rule create_tree:
      input:
          f"{config['outdir']}/results/{DATESTRING['today']}.updateriboprotdedupe.aln"
      output:
          f"{config['outdir']}/results/{DATESTRING['today']}.updateriboprotdedupe.aln.treefile"
      params:
          tree_type = config['tree_type']['options'],
          input_type = config['ribo_name_field']['options'],
          threads = config['threads']
      log:
          f"{config['outdir']}/logs/create_tree.log"
      run:
          if params.tree_type == 'iqtree' and params.input_type == 'protein':
              shell("(iqtree -bb 1000 -alrt 1000 -nm 500 -m LG -nt {threads} -s {input} > {log})")
          elif params.tree_type == 'iqtree' and params.input_type == 'dna':
              shell("(iqtree -bb 1000 -alrt 1000 -nm 500 -m GTR -nt {threads} -s {input} > {log})")
          else:
              shell("(fasttree < {input} > {output}) 2>> {log}")

rule report:
      input:
          f"{config['outdir']}/results/{DATESTRING['today']}.updateriboprotdedupe.aln.treefile"
      output:
          f"{config['outdir']}/results/report.html"
      run:
         from snakemake.utils import report
         with open(input[0]) as aln:
            n_strains = sum(1 for a in aln if a.startswith('>'))
         report("""A workflow initially formulated for downloading Non-aureus Staph genomes, processing to extract ribosomal protein sequences, deduplicating, aligning and creating a phylogenetic tree""",output[0], T1=input[0])
